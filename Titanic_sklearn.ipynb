{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TtFaVaRsPv4Uvfq4SxeBVbtTAxBrVTCz",
      "authorship_tag": "ABX9TyNGyLc+U+2phUJPBkZFlhp/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgEIHl57ETDm"
      },
      "outputs": [],
      "source": [
        "#importando as bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importando dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/titanic.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "y030lO2yEVJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retirar coluna Survived do X\n",
        "x = df.drop(columns=['Survived'],axis=1)\n",
        "#Deixar somente coluna Survived no y\n",
        "y = df['Survived']"
      ],
      "metadata": {
        "id": "Tj6lnPuHF5y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fazer divisão de x e y em 50%\n",
        "train_x, test_x, train_y, test_y = train_test_split(x,y,test_size=0.5)"
      ],
      "metadata": {
        "id": "Cz8p3rUHGZUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificando o treino x\n",
        "train_x.shape"
      ],
      "metadata": {
        "id": "JQQjhpGlHDdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificando a segmentação de teste 50%\n",
        "test_x.shape"
      ],
      "metadata": {
        "id": "ZEpLxrh2HcvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removendo colunas que não vou utiilzar\n",
        "train_x = train_x.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)\n",
        "test_x = test_x.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)"
      ],
      "metadata": {
        "id": "zlYKHBTKHt_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificando valores vazios\n",
        "pd.isna(test_x).sum().to_frame(\"Valor Vazio\")"
      ],
      "metadata": {
        "id": "TTp4jc7mIfBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pegar media das idades, e o tamanho delas, e preencher onde tiver valor vazio\n",
        "train_x['Age'].fillna(train_x['Age'].mean(), inplace = True)\n",
        "#Usar a média do treino no teste, por ter uma porcentagem maior.\n",
        "test_x['Age'].fillna(train_x['Age'].mean(), inplace = True)\n",
        "\n",
        "#pegando quem tem maior ocorrência, e preencher os vazios. \n",
        "train_x['Embarked'].fillna(train_x['Embarked'].mode()[0], inplace = True)\n",
        "# Usar mode do treino\n",
        "test_x['Embarked'].fillna(train_x['Embarked'].mode()[0], inplace = True)"
      ],
      "metadata": {
        "id": "WM9xft5NJpYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tratando variáveis numéricas, utilizando o MinMaxScaler para normalizar as escalas das variáveis.\n",
        "train_x[['Age', 'Fare']] = MinMaxScaler().fit_transform(train_x[['Age', 'Fare']])\n",
        "test_x[['Age', 'Fare']] = MinMaxScaler().fit_transform(test_x[['Age', 'Fare']])"
      ],
      "metadata": {
        "id": "OhKISAaGMXHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converter variáveis categoricas em numéricas\n",
        "train_x = pd.get_dummies(train_x, columns=['Pclass', 'Sex', 'SibSp','Parch', 'Embarked'])\n",
        "test_x = pd.get_dummies(test_x, columns=['Pclass', 'Sex', 'SibSp','Parch', 'Embarked'])\n",
        "#alinhando treino e teste para que o número de colunas sejam iguais.\n",
        "train_x, test_x = train_x.align(test_x, join = 'inner', axis = 1)"
      ],
      "metadata": {
        "id": "jzxHYcPkNpR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RT = MLPClassifier(max_iter = 1000, verbose = True, tol=0.0000100,  learning_rate_init=0.001,hidden_layer_sizes =(20,100))\n",
        "RT.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "kokWF_YCd71o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Acurácia, Precisão e Recall do treino.\n",
        "metricas = {\n",
        "            'Acuracia': RT.score(train_x, train_y),\n",
        "            'Precisão': precision_score(train_y, RT.predict(train_x)),\n",
        "            'Recall': recall_score(train_y, RT.predict(train_x))\n",
        "            }\n",
        "dados = pd.DataFrame(metricas, columns = ['Acuracia', 'Precisão', 'Recall'], index = ['RT'])\n",
        "dados"
      ],
      "metadata": {
        "id": "ZrRpP4O2P5GF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}